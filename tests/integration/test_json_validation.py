"""
Teste de Valida√ß√£o Final - Arquivos JSON do Sistema Bradax
=========================================================

Valida a integridade e consist√™ncia dos arquivos de dados:
- projects.json (configura√ß√µes de projetos)
- guardrails.json (regras de seguran√ßa) 
- telemetry.json (logs de telemetria)
- llm_models.json (modelos dispon√≠veis)

üö® IMPORTANTE: Testa dados reais sem mocks
"""

import json
import pytest
import os
from pathlib import Path
from typing import Dict, Any, List
from datetime import datetime

# Setup de paths
test_dir = Path(__file__).parent.parent
broker_dir = test_dir.parent / "bradax-broker"
data_dir = broker_dir / "data"

class TestJSONDataValidation:
    """Valida√ß√£o rigorosa dos arquivos JSON de dados"""
    
    def setup_method(self):
        """Setup para cada teste"""
        print(f"üìÇ Validando dados em: {data_dir}")
        
        # Criar diret√≥rio de dados se n√£o existe
        data_dir.mkdir(parents=True, exist_ok=True)
        
        # Arquivos obrigat√≥rios
        self.required_files = {
            "projects.json": data_dir / "projects.json",
            "guardrails.json": data_dir / "guardrails.json", 
            "telemetry.json": data_dir / "telemetry.json",
            "llm_models.json": data_dir / "llm_models.json"
        }
    
    def test_projects_json_structure(self):
        """
        Validar estrutura e conte√∫do do projects.json
        
        Esperado:
        - Lista de projetos v√°lidos
        - Projeto de teste com gpt-4.1-nano permitido
        - Campos obrigat√≥rios presentes
        """
        projects_file = self.required_files["projects.json"]
        
        if not projects_file.exists():
            # Criar arquivo padr√£o se n√£o existir
            default_projects = [
                {
                    "project_id": "proj_test_bradax_2025",
                    "project_name": "Bradax Test Project",
                    "status": "active",
                    "allowed_llms": ["gpt-4.1-nano"],
                    "project_token": "bradax_test_token_2025_secure",
                    "created_at": datetime.now().isoformat(),
                    "telemetry_enabled": True,
                    "guardrails_enabled": True
                }
            ]
            
            with open(projects_file, 'w', encoding='utf-8') as f:
                json.dump(default_projects, f, indent=2, ensure_ascii=False)
            
            print(f"‚úÖ Criado projects.json padr√£o: {projects_file}")
        
        # Validar estrutura
        with open(projects_file, 'r', encoding='utf-8') as f:
            projects_data = json.load(f)
        
        assert isinstance(projects_data, list), "Projects deve ser uma lista"
        assert len(projects_data) > 0, "Deve haver pelo menos um projeto"
        
        # Validar projeto de teste
        test_project = None
        for project in projects_data:
            if project.get("project_id") == "proj_test_bradax_2025":
                test_project = project
                break
        
        assert test_project is not None, "Projeto de teste deve existir"
        
        # Validar campos obrigat√≥rios
        required_fields = [
            "project_id", "project_name", "status", 
            "allowed_llms", "project_token"
        ]
        
        for field in required_fields:
            assert field in test_project, f"Campo obrigat√≥rio ausente: {field}"
        
        # Validar que gpt-4.1-nano est√° permitido
        assert "gpt-4.1-nano" in test_project["allowed_llms"], \
            "gpt-4.1-nano deve estar em allowed_llms"
        
        assert test_project["status"] == "active", "Projeto de teste deve estar ativo"
        
        print(f"‚úÖ Projects.json v√°lido com {len(projects_data)} projetos")
    
    def test_llm_models_json_structure(self):
        """
        Validar estrutura do llm_models.json
        
        Esperado:
        - Lista de modelos LLM
        - gpt-4.1-nano presente e habilitado
        - Campos de configura√ß√£o corretos
        """
        models_file = self.required_files["llm_models.json"]
        
        if not models_file.exists():
            # Criar arquivo padr√£o
            default_models = [
                {
                    "model_id": "gpt-4.1-nano",
                    "provider": "openai",
                    "enabled": True,
                    "max_tokens": 4096,
                    "supports_streaming": True,
                    "cost_per_1k_tokens": 0.002,
                    "description": "GPT-4.1 Nano - Modelo otimizado para governan√ßa"
                }
            ]
            
            with open(models_file, 'w', encoding='utf-8') as f:
                json.dump(default_models, f, indent=2, ensure_ascii=False)
            
            print(f"‚úÖ Criado llm_models.json padr√£o: {models_file}")
        
        # Validar estrutura
        with open(models_file, 'r', encoding='utf-8') as f:
            models_data = json.load(f)
        
        assert isinstance(models_data, list), "Models deve ser uma lista"
        
        # Encontrar gpt-4.1-nano
        gpt_nano = None
        for model in models_data:
            if model.get("model_id") == "gpt-4.1-nano":
                gpt_nano = model
                break
        
        assert gpt_nano is not None, "gpt-4.1-nano deve estar no cat√°logo"
        assert gpt_nano["enabled"] is True, "gpt-4.1-nano deve estar habilitado"
        assert gpt_nano["provider"] == "openai", "Provider deve ser openai"
        
        print(f"‚úÖ LLM models.json v√°lido: gpt-4.1-nano dispon√≠vel")
    
    def test_guardrails_json_structure(self):
        """
        Validar estrutura do guardrails.json
        
        Esperado:
        - Lista de regras de guardrail
        - Regras obrigat√≥rias presentes (Python, dados pessoais)
        - Configura√ß√£o por projeto
        """
        guardrails_file = self.required_files["guardrails.json"]
        
        if not guardrails_file.exists():
            # Criar arquivo padr√£o
            default_guardrails = [
                {
                    "guardrail_id": "block_python_code",
                    "project_id": "proj_test_bradax_2025",
                    "rule_type": "content_pattern",
                    "pattern": r"(def |class |import |from .* import)",
                    "action": "block",
                    "enabled": True,
                    "description": "Bloqueia c√≥digo Python em requests",
                    "severity": "high"
                },
                {
                    "guardrail_id": "block_personal_data",
                    "project_id": "proj_test_bradax_2025", 
                    "rule_type": "content_pattern",
                    "pattern": r"(\b\d{3}-\d{2}-\d{4}\b|\b[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}\b)",
                    "action": "block",
                    "enabled": True,
                    "description": "Bloqueia CPF e emails",
                    "severity": "critical"
                }
            ]
            
            with open(guardrails_file, 'w', encoding='utf-8') as f:
                json.dump(default_guardrails, f, indent=2, ensure_ascii=False)
            
            print(f"‚úÖ Criado guardrails.json padr√£o: {guardrails_file}")
        
        # Validar estrutura
        with open(guardrails_file, 'r', encoding='utf-8') as f:
            guardrails_data = json.load(f)
        
        assert isinstance(guardrails_data, list), "Guardrails deve ser uma lista"
        
        # Verificar regras obrigat√≥rias
        rule_ids = [g.get("guardrail_id") for g in guardrails_data]
        
        assert "block_python_code" in rule_ids, "Regra de bloqueio Python deve existir"
        assert "block_personal_data" in rule_ids, "Regra de dados pessoais deve existir"
        
        print(f"‚úÖ Guardrails.json v√°lido com {len(guardrails_data)} regras")
    
    def test_telemetry_json_structure(self):
        """
        Validar estrutura do telemetry.json
        
        Esperado:
        - Lista de logs de telemetria (pode estar vazia)
        - Estrutura de log v√°lida se houver dados
        """
        telemetry_file = self.required_files["telemetry.json"]
        
        if not telemetry_file.exists():
            # Criar arquivo vazio
            with open(telemetry_file, 'w', encoding='utf-8') as f:
                json.dump([], f, indent=2, ensure_ascii=False)
            
            print(f"‚úÖ Criado telemetry.json vazio: {telemetry_file}")
        
        # Validar estrutura
        with open(telemetry_file, 'r', encoding='utf-8') as f:
            telemetry_data = json.load(f)
        
        assert isinstance(telemetry_data, list), "Telemetry deve ser uma lista"
        
        # Se houver dados, validar estrutura
        if len(telemetry_data) > 0:
            sample_log = telemetry_data[0]
            
            required_fields = [
                "telemetry_id", "project_id", "timestamp", 
                "model_used", "status_code"
            ]
            
            for field in required_fields:
                assert field in sample_log, f"Campo obrigat√≥rio no log: {field}"
        
        print(f"‚úÖ Telemetry.json v√°lido com {len(telemetry_data)} logs")
    
    def test_all_json_files_valid_format(self):
        """
        Verificar que todos os arquivos s√£o JSON v√°lidos
        
        Esperado:
        - Todos os arquivos podem ser lidos sem erro
        - N√£o h√° corrup√ß√£o de dados
        """
        validation_results = {}
        
        for file_name, file_path in self.required_files.items():
            try:
                if file_path.exists():
                    with open(file_path, 'r', encoding='utf-8') as f:
                        json.load(f)
                    validation_results[file_name] = True
                else:
                    validation_results[file_name] = False
                    
            except json.JSONDecodeError as e:
                validation_results[file_name] = f"Erro JSON: {e}"
            except Exception as e:
                validation_results[file_name] = f"Erro geral: {e}"
        
        # Verificar resultados
        for file_name, result in validation_results.items():
            if result is True:
                print(f"‚úÖ {file_name}: JSON v√°lido")
            else:
                print(f"‚ùå {file_name}: {result}")
                assert False, f"Arquivo {file_name} com problema: {result}"
    
    def test_data_directory_permissions(self):
        """
        Verificar permiss√µes do diret√≥rio de dados
        
        Esperado:
        - Diret√≥rio existe e √© acess√≠vel
        - Permiss√µes de leitura/escrita
        """
        assert data_dir.exists(), f"Diret√≥rio de dados deve existir: {data_dir}"
        assert data_dir.is_dir(), f"Deve ser um diret√≥rio: {data_dir}"
        
        # Testar cria√ß√£o de arquivo tempor√°rio (permiss√£o de escrita)
        test_file = data_dir / "test_permissions.tmp"
        try:
            with open(test_file, 'w') as f:
                f.write("test")
            
            # Testar leitura
            with open(test_file, 'r') as f:
                content = f.read()
                assert content == "test", "Conte√∫do deve ser lido corretamente"
            
            # Limpar arquivo de teste
            test_file.unlink()
            
            print(f"‚úÖ Permiss√µes de diret√≥rio OK: {data_dir}")
            
        except Exception as e:
            assert False, f"Erro de permiss√µes no diret√≥rio {data_dir}: {e}"


# Configura√ß√£o para pytest
pytestmark = pytest.mark.json_validation


# Executar se chamado diretamente
if __name__ == "__main__":
    pytest.main([__file__, "-v", "--tb=short"])
