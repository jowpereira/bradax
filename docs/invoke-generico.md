# MÃ©todo invoke_generic - Wrapper LangChain Bradax

## VisÃ£o Geral

O mÃ©todo `invoke_generic()` Ã© o ponto central de integraÃ§Ã£o entre o SDK bradax e o wrapper LangChain. Ele fornece uma interface Ãºnica e flexÃ­vel para executar diferentes tipos de operaÃ§Ãµes LLM, mantendo todos os guardrails, telemetria e governanÃ§a centralizados no hub.

## CaracterÃ­sticas Principais

### ðŸ”§ **Flexibilidade Total**
- Suporte a mÃºltiplas operaÃ§Ãµes: `chat`, `completion`, `batch`, `stream`, `embedding`
- Payload completamente customizÃ¡vel para diferentes necessidades
- Compatibilidade com qualquer formato de entrada do LangChain

### ðŸ›¡ï¸ **GovernanÃ§a Centralizada**
- Guardrails aplicados automaticamente pelo hub (nÃ£o contornÃ¡veis)
- Telemetria extensiva e obrigatÃ³ria
- AutenticaÃ§Ã£o e autorizaÃ§Ã£o por projeto
- Auditoria completa de todas as operaÃ§Ãµes

### ðŸ“Š **Telemetria AutomÃ¡tica**
- Rastreamento de tempo de resposta
- Contagem de tokens utilizados
- Logs estruturados de erros e sucessos
- MÃ©tricas de performance por projeto

## Interface do MÃ©todo

### SDK (Cliente)

```python
def invoke_generic(
    self,
    operation: str,          # Tipo de operaÃ§Ã£o
    model_id: str,          # ID do modelo
    payload: Dict[str, Any], # Payload flexÃ­vel
    request_id: Optional[str] = None  # ID opcional
) -> Dict[str, Any]:
```

### Broker (ServiÃ§o)

```python
async def invoke_generic(
    self,
    operation: str,
    model_id: str,
    payload: Dict[str, Any],
    project_id: Optional[str] = None,
    request_id: Optional[str] = None
) -> Dict[str, Any]:
```

### Provider (LangChain)

```python
async def invoke_generic(
    self, 
    operation: str,
    model_id: str,
    payload: Dict[str, any],
    request_id: Optional[str] = None
) -> Dict[str, any]:
```

## OperaÃ§Ãµes Suportadas

### 1. **Chat/Completion**
```python
payload = {
    "prompt": "Sua pergunta aqui",
    "system_prompt": "Contexto do sistema",
    "max_tokens": 1000,
    "temperature": 0.7
}

result = client.invoke_generic("chat", "gpt-3.5-turbo", payload)
```

### 2. **Batch Processing**
```python
payload = {
    "batch_requests": [
        {"prompt": "Pergunta 1", "max_tokens": 50},
        {"prompt": "Pergunta 2", "max_tokens": 50},
        {"prompt": "Pergunta 3", "max_tokens": 50}
    ]
}

result = client.invoke_generic("batch", "gpt-3.5-turbo", payload)
```

### 3. **Stream (Simulado)**
```python
payload = {
    "prompt": "Conte uma histÃ³ria longa",
    "stream_config": {"chunk_size": 100}
}

result = client.invoke_generic("stream", "gpt-3.5-turbo", payload)
```

### 4. **Custom/Advanced**
```python
payload = {
    "messages": [
        {"role": "system", "content": "VocÃª Ã© um especialista"},
        {"role": "user", "content": "Pergunta complexa"}
    ],
    "parameters": {
        "temperature": 0.3,
        "top_p": 0.9,
        "frequency_penalty": 0.1
    },
    "metadata": {
        "experiment_id": "exp_001",
        "research_area": "NLP"
    }
}

result = client.invoke_generic("completion", "gpt-4", payload)
```

## Formato de Resposta

```python
{
    "success": True,
    "request_id": "12345-abcde-67890",
    "operation": "chat",
    "model_used": "gpt-3.5-turbo",
    "provider": "openai",
    "response_time_ms": 1250,
    "langchain_used": True,
    "service_timestamp": "2025-07-28T15:30:45Z",
    "project_id": "proj_marketing_001",
    "broker_version": "1.0.0",
    
    # Dados especÃ­ficos da operaÃ§Ã£o
    "response_text": "Resposta do modelo...",
    "finish_reason": "stop",
    "usage": {
        "total_tokens": 150,
        "prompt_tokens": 100,
        "completion_tokens": 50
    },
    
    # Para batch operations
    "batch_results": [...],
    "total_requests": 3,
    "successful_requests": 3
}
```

## Fluxo de ExecuÃ§Ã£o

### 1. **SDK â†’ Broker**
```
Cliente SDK              Broker API
     |                        |
     | POST /api/v1/llm/invoke |
     |----------------------->|
     |                        | âœ“ Validar token
     |                        | âœ“ Aplicar guardrails
     |                        | âœ“ Registrar telemetria
     |                        |
```

### 2. **Broker â†’ LangChain**
```
Broker Service           LangChain Provider
     |                        |
     | invoke_generic()       |
     |----------------------->|
     |                        | âœ“ Validar modelo
     |                        | âœ“ Executar operaÃ§Ã£o
     |                        | âœ“ Retornar resultado
     |                        |
```

### 3. **Resposta Completa**
```
     |<-----------------------|
     | âœ“ Adicionar metadados   |
     | âœ“ Registrar telemetria  |
     | âœ“ Formatar resposta     |
     |<-----------------------|
```

## Vantagens da Arquitetura

### ðŸŽ¯ **Para Desenvolvedores**
- Interface Ãºnica e consistente
- Flexibilidade total de payload
- Tratamento automÃ¡tico de erros
- NÃ£o precisam se preocupar com governanÃ§a

### ðŸ›¡ï¸ **Para GovernanÃ§a**
- Controle centralizado de todas as operaÃ§Ãµes
- Telemetria obrigatÃ³ria e nÃ£o contornÃ¡vel
- Auditoria completa de uso de LLMs
- AplicaÃ§Ã£o consistente de polÃ­ticas

### ðŸ”§ **Para IntegraÃ§Ã£o LangChain**
- Compatibilidade nativa com todas as features
- Suporte a operaÃ§Ãµes batch e streaming
- Flexibilidade para novos tipos de operaÃ§Ã£o
- Wrapper transparente sem overhead

## Casos de Uso

### 1. **Desenvolvimento RAG**
```python
# Embedding de documentos
payload = {"documents": [...], "chunk_size": 1000}
embeddings = client.invoke_generic("embedding", "text-embedding-ada-002", payload)

# Consulta com contexto
payload = {
    "query": "Pergunta do usuÃ¡rio",
    "context_docs": [...],
    "system_prompt": "Use apenas o contexto fornecido"
}
response = client.invoke_generic("chat", "gpt-4", payload)
```

### 2. **Processamento em Lote**
```python
# AnÃ¡lise de sentimentos em massa
documents = ["Doc 1", "Doc 2", ..., "Doc N"]
payload = {
    "batch_requests": [
        {"prompt": f"Analise o sentimento: {doc}", "max_tokens": 10}
        for doc in documents
    ]
}
results = client.invoke_generic("batch", "gpt-3.5-turbo", payload)
```

### 3. **Chains Complexas**
```python
# Chain customizada com mÃºltiplas etapas
payload = {
    "chain_type": "custom",
    "steps": [
        {"operation": "summarize", "input": "documento_longo.txt"},
        {"operation": "translate", "target_language": "en"},
        {"operation": "sentiment", "output_format": "json"}
    ]
}
result = client.invoke_generic("chain", "gpt-4", payload)
```

## ImplementaÃ§Ã£o TÃ©cnica

### ValidaÃ§Ã£o de Entrada
```python
# SDK
if not operation or not model_id:
    raise BradaxValidationError("ParÃ¢metros obrigatÃ³rios")

if not isinstance(payload, dict):
    raise BradaxValidationError("Payload deve ser dict")
```

### Tratamento de Erros
```python
# Broker
try:
    result = await provider.invoke_generic(...)
    await self._log_telemetry(result)
    return result
except Exception as e:
    error_result = self._create_error_result(str(e))
    await self._log_telemetry(error_result)
    return error_result
```

### Telemetria AutomÃ¡tica
```python
telemetry_data = {
    "operation_type": "invoke_generic",
    "langchain_operation": operation,
    "project_id": project_id,
    "timestamp": datetime.utcnow().isoformat(),
    "success": result.get("success"),
    "response_time_ms": result.get("response_time_ms"),
    "tokens_used": result.get("usage", {}).get("total_tokens", 0)
}
```

## PrÃ³ximos Passos

1. **Implementar operaÃ§Ãµes de embedding**
2. **Adicionar suporte a streaming real**
3. **Implementar chains customizadas**
4. **Adicionar cache de respostas**
5. **Implementar rate limiting por operaÃ§Ã£o**

## ConclusÃ£o

O mÃ©todo `invoke_generic()` representa a evoluÃ§Ã£o natural da integraÃ§Ã£o LangChain no ecosistema bradax, oferecendo:

- **Flexibilidade mÃ¡xima** para desenvolvedores
- **GovernanÃ§a robusta** para administradores
- **Compatibilidade total** com LangChain
- **Telemetria extensiva** para monitoramento
- **Escalabilidade** para operaÃ§Ãµes complexas

Ã‰ o wrapper ideal para uso corporativo de LLMs com controle centralizado.
