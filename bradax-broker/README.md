# Bradax Broker - Hub Corporativo de LLM

> **Sistema empresarial de orquestraÃ§Ã£o de LLM com autenticaÃ§Ã£o por projeto, guardrails automÃ¡ticos e telemetria completa.**

## ğŸ—ï¸ VisÃ£o Geral Arquitetural

O Bradax Broker Ã© um proxy corporativo que centraliza o acesso a modelos de LLM, aplicando polÃ­ticas de governanÃ§a, autenticaÃ§Ã£o baseada em projetos e coleta de telemetria em tempo real.

```mermaid
graph TB
    SDK[bradax SDK] -->|Token de Projeto| AUTH[AutenticaÃ§Ã£o]
    AUTH --> GUARD[Guardrails]
    GUARD --> LLM[ServiÃ§o LLM]
    LLM --> PROVIDER[Provider LangChain]
    PROVIDER --> OPENAI[OpenAI API]
    
    AUTH --> TELEM[Telemetria]
    GUARD --> TELEM
    LLM --> TELEM
    TELEM --> STORAGE[Storage JSON]
    
    subgraph "Middleware Stack"
        SECURITY[Security]
        CORS[CORS]
        LOGGING[Logging]
        RATE[Rate Limiting]
    end
```

## ğŸ¯ Casos de Uso Corporativos

### 1. IntegraÃ§Ã£o por Projetos
```python
# SDK se autentica com token do projeto
client = BradaxClient(
    project_token="proj_acme_2025_ai_assistant_001",
    broker_url="https://llm.empresa.com"
)

# Cada projeto tem seus modelos permitidos
response = client.run_llm(
    prompt="Analise este documento corporativo...",
    model="gpt-4o-mini"  # Deve estar na lista do projeto
)
```

### 2. Guardrails AutomÃ¡ticos
```python
# PolÃ­tica aplicada automaticamente por projeto
{
    "content_filters": ["pii", "confidential"],
    "max_tokens": 2000,
    "allowed_domains": ["empresa.com"],
    "compliance": "LGPD"
}
```

### 3. Telemetria e Auditoria
```python
# Coleta automÃ¡tica de mÃ©tricas
{
    "request_id": "req_789xyz",
    "project": "acme_ai_assistant", 
    "model": "gpt-4o-mini",
    "tokens_used": 1250,
    "cost": 0.15,
    "timestamp": "2025-07-29T01:15:30Z",
    "user_department": "marketing"
}
```

## ğŸ› ï¸ Endpoints Principais

### AutenticaÃ§Ã£o e Projetos
```http
POST /api/v1/auth/validate
Authorization: Bearer proj_token_here
```

### OperaÃ§Ãµes LLM
```http
# ExecuÃ§Ã£o de modelo
POST /api/v1/llm/invoke
{
    "operation": "chat",
    "model": "gpt-4o-mini", 
    "payload": {
        "prompt": "Sua pergunta aqui",
        "max_tokens": 1000
    },
    "project_id": "acme_ai_assistant"
}

# Listar modelos disponÃ­veis
GET /api/v1/llm/models?project_id=acme_ai_assistant
```

### Sistema e Telemetria
```http
# Status do sistema
GET /api/v1/system/health

# MÃ©tricas do projeto
GET /api/v1/system/metrics?project_id=acme_ai_assistant

# Telemetria em tempo real
GET /api/v1/system/telemetry?period=1d
```

### Gerenciamento de Projetos
```http
# InformaÃ§Ãµes do projeto
GET /api/v1/management/projects/{project_id}

# Configurar guardrails
PUT /api/v1/management/projects/{project_id}/guardrails
{
    "content_filters": ["pii"],
    "max_daily_tokens": 50000,
    "allowed_models": ["gpt-4o-mini", "gpt-3.5-turbo"]
}
```

## ğŸ” SeguranÃ§a e AutenticaÃ§Ã£o

### Modelo de AutenticaÃ§Ã£o
- **Por Projeto:** Cada projeto corporativo tem token Ãºnico
- **ValidaÃ§Ã£o ContÃ­nua:** Tokens validados a cada requisiÃ§Ã£o
- **Escopo Limitado:** Projetos sÃ³ acessam seus recursos autorizados

### Headers ObrigatÃ³rios
```http
Authorization: Bearer proj_acme_2025_ai_assistant_001
Content-Type: application/json
X-Project-Token: proj_acme_2025_ai_assistant_001
```

### Middleware de SeguranÃ§a
1. **SecurityMiddleware:** Headers de seguranÃ§a, rate limiting
2. **AuthenticationMiddleware:** ValidaÃ§Ã£o de tokens
3. **LoggingMiddleware:** Auditoria completa de requisiÃ§Ãµes
4. **CORSMiddleware:** Controle de origens permitidas

## ğŸ“Š Sistema de Telemetria

### Coleta AutomÃ¡tica
- **RequisiÃ§Ãµes:** Todas as chamadas sÃ£o registradas
- **Performance:** LatÃªncia, throughput, errors
- **Custos:** Tokens consumidos por projeto/modelo
- **Compliance:** Logs para auditoria corporativa

### MÃ©tricas DisponÃ­veis
```json
{
    "project_metrics": {
        "total_requests": 15420,
        "total_tokens": 2500000,
        "total_cost": 375.50,
        "avg_latency_ms": 850,
        "error_rate": 0.02
    },
    "model_usage": {
        "gpt-4o-mini": {
            "requests": 12000,
            "tokens": 1800000,
            "cost": 270.00
        },
        "gpt-3.5-turbo": {
            "requests": 3420,
            "tokens": 700000,
            "cost": 105.50
        }
    }
}
```

## ğŸ›¡ï¸ Sistema de Guardrails

### Guardrails AutomÃ¡ticos
- **ValidaÃ§Ã£o de ConteÃºdo:** Filtros de PII, conteÃºdo imprÃ³prio
- **Limites de Uso:** Tokens por perÃ­odo, requisiÃ§Ãµes por minuto
- **Compliance:** LGPD, GDPR, polÃ­ticas corporativas
- **Modelo Apropriado:** ValidaÃ§Ã£o de modelo vs projeto

### ConfiguraÃ§Ã£o por Projeto
```json
{
    "guardrails": {
        "content_policy": {
            "filter_pii": true,
            "filter_confidential": true,
            "max_content_length": 10000
        },
        "usage_limits": {
            "max_tokens_per_day": 100000,
            "max_requests_per_minute": 50,
            "max_cost_per_month": 1000.00
        },
        "compliance": {
            "data_residency": "BR",
            "audit_level": "full",
            "retention_days": 90
        }
    }
}
```

## ğŸ”§ IntegraÃ§Ã£o com LangChain

### Providers Suportados
- **OpenAI:** GPT-4o, GPT-4o-mini, GPT-3.5-turbo
- **Anthropic:** Claude (futuro)
- **Google:** Gemini (futuro)

### ConfiguraÃ§Ã£o de Modelos
```python
# ConfiguraÃ§Ã£o no projeto
{
    "allowed_models": [
        {
            "model_id": "gpt-4o-mini",
            "max_tokens": 4096,
            "cost_per_token": 0.00015,
            "enabled": true
        }
    ]
}
```

## ğŸ“ˆ Monitoramento e Observabilidade

### Health Checks
```http
GET /health
{
    "status": "healthy",
    "timestamp": "2025-07-29T01:15:30Z",
    "services": {
        "llm_service": "up",
        "storage": "up", 
        "auth": "up"
    }
}
```

### Logs Estruturados
```json
{
    "timestamp": "2025-07-29T01:15:30Z",
    "level": "INFO",
    "service": "llm_controller",
    "request_id": "req_789xyz",
    "project_id": "acme_ai_assistant",
    "action": "llm_invoke",
    "model": "gpt-4o-mini",
    "tokens": 1250,
    "latency_ms": 850,
    "status": "success"
}
```

## ğŸš€ Casos de Uso AvanÃ§ados

### 1. Batch Processing
```python
# Processar mÃºltiplos documentos
results = client.batch_process([
    {"prompt": "Analise documento 1", "model": "gpt-4o-mini"},
    {"prompt": "Analise documento 2", "model": "gpt-4o-mini"},
    {"prompt": "Analise documento 3", "model": "gpt-4o-mini"}
])
```

### 2. Streaming Responses
```python
# Resposta em tempo real
for chunk in client.stream_llm(
    prompt="Escreva um relatÃ³rio detalhado...",
    model="gpt-4o"
):
    print(chunk, end="")
```

### 3. FunÃ§Ã£o Calling
```python
# ExecuÃ§Ã£o de funÃ§Ãµes
response = client.run_llm(
    prompt="Qual a previsÃ£o do tempo em SÃ£o Paulo?",
    model="gpt-4o",
    functions=[{
        "name": "get_weather",
        "description": "Obter previsÃ£o do tempo",
        "parameters": {"city": "string"}
    }]
)
```

## ğŸ”„ Arquitetura de Dados

### Fluxo de Dados
```
Cliente â†’ Auth â†’ Guardrails â†’ LLM â†’ Provider â†’ Response
    â†“        â†“         â†“        â†“
  Telemetria â† Storage â† Logs â† Metrics
```

### PersistÃªncia
- **Projetos:** `data/projects.json`
- **Guardrails:** `data/guardrails.json` 
- **Telemetria:** `data/telemetry.json`
- **Sistema:** `data/system_info.json`

## ğŸ¢ GovernanÃ§a Corporativa

### PolÃ­ticas Implementadas
- **AutenticaÃ§Ã£o ObrigatÃ³ria:** Nenhuma requisiÃ§Ã£o sem token
- **Auditoria Completa:** Logs de todas as operaÃ§Ãµes
- **Controle de Custos:** Limites por projeto e perÃ­odo
- **Compliance AutomÃ¡tico:** Filtros e validaÃ§Ãµes obrigatÃ³rias

### RelatÃ³rios Executivos
- **Dashboard de Uso:** MÃ©tricas por departamento
- **AnÃ¡lise de Custos:** ROI por projeto
- **Compliance Reports:** Auditoria para certificaÃ§Ãµes
- **Performance Analytics:** OtimizaÃ§Ã£o de uso

---

> **ğŸ’¡ Nota:** Este broker foi projetado para ambientes corporativos que exigem controle total sobre o uso de LLM, com foco em seguranÃ§a, auditoria e governanÃ§a.
